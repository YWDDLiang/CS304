{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da137916-9470-4cbf-b993-ad76484a593d",
   "metadata": {},
   "source": [
    "# Functions in project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200bc5de-8a34-44ba-b06a-16a95e63a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyboard\n",
    "import time\n",
    "import wave\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Divide signal data into 20ms segements with 10ms interval for every two consecutive ones \n",
    "def create_segments(signal,sample_rate,width=10):\n",
    "    num=int(width*sample_rate/1000)\n",
    "    # first divide signal into 10ms segments\n",
    "    ten_ms_segments = [signal[i:i+num] for i in range(0, len(signal), num)]\n",
    "    twenty_ms_segments =[]\n",
    "    for j in range(len(ten_ms_segments)):\n",
    "        if j!=0:\n",
    "            l1=ten_ms_segments[j-1]\n",
    "            l2=ten_ms_segments[j]\n",
    "            l=[0 for i in range(num*2)]\n",
    "            for k in range(len(l1)):\n",
    "                l[k]=l1[k]\n",
    "                l[k+len(l1)]=l2[k]\n",
    "            twenty_ms_segments.append(l)\n",
    "    return twenty_ms_segments\n",
    "\n",
    "# Preemphasize each segement\n",
    "def Preemphasizing(segment):\n",
    "    pre=np.zeros(len(segment))\n",
    "    pre[0]=segment[0]\n",
    "    for i in range(1,len(segment)):\n",
    "        pre[i]=segment[i]-0.95*segment[i-1]\n",
    "    return pre\n",
    "\n",
    "# Window each preemphasized segement\n",
    "def windowing(pre):\n",
    "    pre=pre*np.hamming(len(pre))\n",
    "    return pre\n",
    "\n",
    "# Zero pad each windowed segement\n",
    "def zero_padding(windowed):\n",
    "    #zero padding for FFT\n",
    "    length=512\n",
    "    windowed_len=len(windowed)\n",
    "    padding_len=length-windowed_len\n",
    "    zeros=np.zeros((padding_len,))\n",
    "    zero_padded=np.concatenate((windowed,zeros))\n",
    "    return zero_padded\n",
    "\n",
    "# Calculate the power spectrum of a segement\n",
    "def FFT(frame):\n",
    "    length=512\n",
    "    fft=np.fft.rfft(frame, length)\n",
    "    magnitude = np.abs(fft)\n",
    "    power = ((1.0 / length) * ((magnitude) ** 2)) \n",
    "\n",
    "    return power\n",
    "\n",
    "# Mel warping function\n",
    "def warping_function(Hz):\n",
    "    Mel = 2595 * np.log10(1+Hz/700)\n",
    "    return Mel\n",
    "# inverse function\n",
    "def inverse_warping(Mel):\n",
    "    Hz = 700*(np.power(10,Mel/2595)-1) \n",
    "    return Hz\n",
    "\n",
    "# calculate mel spectra and log mel spectra\n",
    "def filterbanks(power,filter_num,minHz=133.33,maxHz=6855.4976,length=512):\n",
    "    maxMel=warping_function(maxHz)\n",
    "    minMel=warping_function(minHz)\n",
    "    #get start and end points of triangle filters in Mel\n",
    "    pointsInMel=np.linspace(minMel,maxMel,filter_num+2)\n",
    "    #get start and end points of triangle filters in Hz\n",
    "    pointsInHz=inverse_warping(pointsInMel)\n",
    "    #get start and end points of tiangle filters in total 257 points\n",
    "    ranges=np.floor(length/2*pointsInHz/(maxHz-minHz))\n",
    "    #normalize the triangle filters according to the lower bound\n",
    "    ranges=ranges-ranges[0]\n",
    "    #create filter banks with size(number of filters=40, points in power spectrum=257)\n",
    "    filter_banks=np.zeros((filter_num,len(power)))\n",
    "    for i in range(1,filter_num+1): \n",
    "        #get the left half of the traingle\n",
    "        for j in range(int(ranges[i-1]),int(ranges[i])):\n",
    "            filter_banks[i-1,j]=(j-ranges[i-1])/(ranges[i]-ranges[i-1])\n",
    "        #get the right half of the traingle\n",
    "        for j in range(int(ranges[i]),int(ranges[i+1])):\n",
    "            filter_banks[i-1,j]=(ranges[i+1]-j)/(ranges[i+1]-ranges[i])\n",
    "    #mel spectrum\n",
    "    filter_banks=filter_banks.T\n",
    "    Mel=np.dot(power,filter_banks)\n",
    "    Mel=np.where(Mel==0,np.finfo(float).eps,Mel)\n",
    "    #log mel spectrum\n",
    "    Log_Mel=10*np.log(Mel) \n",
    "    return Mel,Log_Mel\n",
    "\n",
    "from scipy.fftpack import dct,idct\n",
    "# use dct to get the cepstral_coefficients\n",
    "def mel_cepstrum(log_mel):\n",
    "    cepstral_coefficients=dct(log_mel,axis=-1, type=2, norm='ortho')\n",
    "    return cepstral_coefficients[:13]\n",
    "\n",
    "# get idct\n",
    "def IDCT(log_mel,num):\n",
    "    IDCT_coefficients=idct(log_mel,type=2, n=num, norm='ortho')\n",
    "    return IDCT_coefficients\n",
    "\n",
    "# get log mel spectrum matrix, mel cpestrum matrix and idct matrix, given segments\n",
    "def get_matrix(segments,num):\n",
    "    Mel_cepstrum_matrix=[]\n",
    "    log_Mel_spectrum_matrix=[]\n",
    "    IDCT_matrix=[]\n",
    "    for i in range(len(segments)):\n",
    "        preemphasized=Preemphasizing(segments[i])\n",
    "        windowed=windowing(preemphasized)\n",
    "        zero_padded=zero_padding(windowed)\n",
    "        power_spectrum=FFT(zero_padded)\n",
    "        Mel_spectrum, log_Mel_spectrum=filterbanks(power_spectrum,num)\n",
    "        log_Mel_spectrum_matrix.append(log_Mel_spectrum)\n",
    "        Mel_cepstrum=mel_cepstrum(log_Mel_spectrum)\n",
    "        Mel_cepstrum_matrix.append(Mel_cepstrum)\n",
    "        IDCT_spectrum=IDCT(Mel_cepstrum,num)\n",
    "        IDCT_matrix.append(IDCT_spectrum)\n",
    "    return log_Mel_spectrum_matrix,Mel_cepstrum_matrix,IDCT_matrix\n",
    "#plot the spectrum and cepstrum\n",
    "def plot_show(matrix, title):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.subplot(311)\n",
    "    plt.imshow(matrix.T, origin='lower')\n",
    "    plt.title(title)\n",
    "\n",
    "#load wav file\n",
    "def load_wav(file_path):\n",
    "    wav_file = wave.open(file_path, 'r')\n",
    "    # Get the audio data\n",
    "    frames = wav_file.readframes(-1)\n",
    "    signal = np.frombuffer(frames, dtype=np.int16)\n",
    "\n",
    "    # Get the sample rate and time axis\n",
    "    sample_rate = wav_file.getframerate()\n",
    "    duration = len(signal) / sample_rate\n",
    "    time = np.linspace(0., duration, len(signal))\n",
    "    \n",
    "    # Close the WAV file\n",
    "    wav_file.close()\n",
    "    return signal, sample_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276066e5-4240-43f6-b905-6dee20b9f4ec",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc56f44-63ac-42d8-9945-703ff9a7d57d",
   "metadata": {},
   "source": [
    "## 1. Mean subtraction and variance normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4938f827-179e-412a-b4cc-aee8f9ce9c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_subtraction(matrix):\n",
    "    means = np.mean(matrix, axis=0)/(np.shape(matrix)[0])\n",
    "    matrix=matrix-means\n",
    "    return matrix\n",
    "\n",
    "def var_normalization(matrix):\n",
    "    sd=np.sqrt(np.sum(np.square(matrix),axis=0)/(np.shape(matrix)[0]))\n",
    "    return matrix*(1/sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c2a33a-fd67-4baa-9136-55375b7beb44",
   "metadata": {},
   "source": [
    "## Get cepstrum feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17376065-c7a8-4c17-9e2e-9e40d278a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cepstrum_features(file):\n",
    "    signal, sample_rate=load_wav(file)\n",
    "    seg=create_segments(signal,sample_rate)\n",
    "    log_mel_spectrum_matrix,mel_cepstrum_matrix,IDCT_matrix=get_matrix(seg,40)\n",
    "    log_mel_spectrum_matrix,mel_cepstrum_matrix,IDCT_matrix=np.array(log_mel_spectrum_matrix),np.array(mel_cepstrum_matrix),np.array(IDCT_matrix)\n",
    "\n",
    "    mean_subtracted=mean_subtraction(mel_cepstrum_matrix)\n",
    "    var_normalized=var_normalization(mean_subtracted)\n",
    "    return var_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45729478-dc68-4808-8d59-f035a8ea9584",
   "metadata": {},
   "source": [
    "## Get MFCC using python_speech_features package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f6e3c-97f1-4e66-a12b-30da6751ecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc\n",
    "def get_MFCC(wavename):#with normalization\n",
    "    import numpy as np\n",
    "    import scipy.io.wavfile as wav\n",
    "    from python_speech_features import mfcc\n",
    "    fs, audio = wav.read(wavename)\n",
    "    feature_mfcc = mfcc(audio, samplerate=fs,\n",
    "                        winlen=0.020,\n",
    "               winstep=0.01,\n",
    "               numcep=13,\n",
    "               nfilt=40,\n",
    "               nfft=512,\n",
    "               lowfreq=133.33,\n",
    "               highfreq=6855.4976,\n",
    "               preemph=0.95,\n",
    "               ceplifter=0,\n",
    "               appendEnergy=False,\n",
    "               winfunc=np.hamming)\n",
    "    mfcc=[]\n",
    "    mfcc.append(np.hstack([feature_mfcc[0],feature_mfcc[0],feature_mfcc[0]]))\n",
    "    for i in range(1,len(feature_mfcc)-1):\n",
    "        delta=np.zeros(13)\n",
    "        for j in range(13):\n",
    "            delta[j]=feature_mfcc[i+1][j]-feature_mfcc[i-1][j]\n",
    "        mfcc.append(np.hstack([feature_mfcc[i],delta]))\n",
    "    mfcc.append(np.hstack([feature_mfcc[-1],feature_mfcc[-1],feature_mfcc[-1]]))\n",
    "\n",
    "    for i in range(1,len(mfcc)-1):\n",
    "        acc=np.zeros(13)\n",
    "        for j in range(13):\n",
    "            acc[j]=mfcc[i+1][13+j]-mfcc[i-1][13+j]\n",
    "        mfcc[i]=np.hstack([mfcc[i],acc])\n",
    "    mfccs=np.array(mfcc)\n",
    "    std=np.std(mfccs)\n",
    "    var=np.var(mfccs,1)\n",
    "    for i in range(len(mfccs)):\n",
    "        for j in range(39):\n",
    "            mfccs[i][j]=mfccs[i][j]/var[i]\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec4ff3c-8f4a-49cb-9960-fce1460e2d0a",
   "metadata": {},
   "source": [
    "## 2. DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44559c0e-a774-4968-9b9c-62d144387f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the Euclidean distance between two feature vectors\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\n",
    "\n",
    "# get DTW distance\n",
    "def DTW(input, template):       \n",
    "    new_array=np.full(len(template),np.inf)\n",
    "    old_array=np.full(len(template),np.inf)\n",
    "    for i in range(len(input)):\n",
    "        if i==0:\n",
    "            old_array[0]=euclidean_distance(input[i],template[0])\n",
    "        else:\n",
    "            for j in range(len(template)):\n",
    "                if j==0:\n",
    "                    new_array[0]=old_array[0]+euclidean_distance(input[i], template[j])\n",
    "                elif j==1:\n",
    "                    cost=min(old_array[j-1],old_array[j])\n",
    "                    new_array[1]=euclidean_distance(input[i],template[j])+cost\n",
    "                else:\n",
    "                    cost=min(old_array[j-1],old_array[j-2],old_array[j])\n",
    "                    new_array[j]=euclidean_distance(input[i],template[j])+cost\n",
    "            old_array=new_array\n",
    "            new_array=np.full(len(template),np.inf)\n",
    "            \n",
    "    # Return the DTW distance\n",
    "    return old_array[len(template)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf67a67-e48f-4156-bef2-ab7c97fb87d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get MFCC of 10 templates\n",
    "template_feature_matrix=[]\n",
    "for i in range(10):\n",
    "    template_feature=get_cepstrum_features('recorded_digits/'+str(i)+'_template.wav')\n",
    "    template_feature_matrix.append(template_feature)\n",
    "dtw_result=np.zeros((10,5))\n",
    "\n",
    "# generate the results for training data and put them in the matrix\n",
    "def DTW_recognition(templates):\n",
    "    result=np.zeros((len(templates),5))\n",
    "    for i in range(len(templates)):\n",
    "        for j in range(1,5):\n",
    "            training_feature=get_cepstrum_features('recorded_digits/'+str(i)+'_training_'+str(j)+'.wav')\n",
    "            dtw=DTW(training_feature,templates[0])\n",
    "            type=0\n",
    "            for k in range(1,10):\n",
    "                cur_dtw=DTW(training_feature,template_feature_matrix[k])\n",
    "                if cur_dtw<dtw:\n",
    "                    dtw=cur_dtw\n",
    "                    type=k\n",
    "            result[i][j-1]=type\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a477845-9287-4040-900b-a079d2b025f4",
   "metadata": {},
   "source": [
    "## Simple DTW accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18178a05-677b-465b-920a-d06ca43e38c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the accuracy and runtime of the DTW\n",
    "start_time = time.time()\n",
    "\n",
    "a = np.arange(10).reshape(10, 1)\n",
    "correct_classifications = np.hstack((a,a,a,a,a))\n",
    "dtw_result=DTW_recognition(template_feature_matrix)\n",
    "print(dtw_result)\n",
    "differing_positions = dtw_result != correct_classifications\n",
    "print('DTW Accuracy:',1-np.sum(differing_positions)/50)\n",
    "\n",
    "end_time = time.time()\n",
    "# Calculate the runtime\n",
    "runtime = end_time - start_time\n",
    "print(\"Runtime: {:.6f} seconds\".format(runtime))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfccb37e-30a1-4529-a13e-55ff6c7a5b24",
   "metadata": {},
   "source": [
    "## 3. Time-synchronous DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f9e41f-80a9-4bc1-9f85-358495a9efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do time synchronous DTW\n",
    "def Time_synchronous_DTW(input,templates):     \n",
    "    template_len=[0]\n",
    "    for i in range(10):\n",
    "        if i==0: template_len.append(np.shape(templates[i])[0])\n",
    "        else: template_len.append(template_len[-1]+np.shape(templates[i])[0])\n",
    "    # template_len = [0, 99, 168, 267, 366, 465, 564, 663, 762, 861, 960]\n",
    "    # use two arrays with the length of input template to record the distance at each position\n",
    "    new_array=np.full(template_len[-1],np.inf)\n",
    "    old_array=np.full(template_len[-1],np.inf)\n",
    "    # i represents the number of vectors in the input\n",
    "    for i in range(len(input)):\n",
    "        if i==0:\n",
    "            for k in range(len(template_len)-1):\n",
    "                old_array[template_len[k]]=euclidean_distance(templates[k][0],input[i])\n",
    "        else:\n",
    "            for k in range(len(template_len)-1):\n",
    "                low=template_len[k]\n",
    "                high=template_len[k+1]\n",
    "                new_array[low]=old_array[low]+euclidean_distance(templates[k][0],input[i])\n",
    "                new_array[low+1]=min(old_array[low+1],old_array[low])+euclidean_distance(templates[k][1],input[i])\n",
    "                for j in range(low+2,high): \n",
    "                    cost=min(old_array[j-2],old_array[j-1],old_array[j])\n",
    "                    new_array[j]=euclidean_distance(templates[k][j-low],input[i])+cost\n",
    "            old_array=new_array\n",
    "            new_array=np.full(template_len[-1],np.inf)\n",
    "            \n",
    "    type=0\n",
    "    dtw=old_array[template_len[1]-1]\n",
    "    for i in range(2,len(template_len)):\n",
    "        dist=old_array[template_len[i]-1]\n",
    "        if dist<dtw:\n",
    "            dtw=dist\n",
    "            type=i-1\n",
    "    return type\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd89970-9dc5-43c7-b31f-2c21e31ef660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get result matrix of TS_DTW\n",
    "def TS_DTW_recognition(templates):\n",
    "    result=np.zeros((len(templates),5))\n",
    "    for i in range(len(templates)):\n",
    "        for j in range(1,6):\n",
    "            training_feature=get_cepstrum_features('recorded_digits/'+str(i)+'_training_'+str(j)+'.wav')\n",
    "            type=Time_synchronous_DTW(training_feature,templates)\n",
    "            result[i][j-1]=type\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c0dc10-10c6-4d19-9f49-d505d0278c4d",
   "metadata": {},
   "source": [
    "## Time-synchronous DTW Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d6d1d5-d22c-4015-802c-b329dba71e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "a = np.arange(10).reshape(10, 1)\n",
    "correct_classifications = np.hstack((a,a,a,a,a))\n",
    "ts_dtw_result=TS_DTW_recognition(template_feature_matrix)\n",
    "print(ts_dtw_result)\n",
    "differing_positions = ts_dtw_result != correct_classifications\n",
    "print('TS_DTW Accuracy:',1-np.sum(differing_positions)/50)\n",
    "\n",
    "end_time = time.time()\n",
    "# Calculate the runtime\n",
    "runtime = end_time - start_time\n",
    "print(\"Runtime: {:.6f} seconds\".format(runtime))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f81707-852b-46f6-805d-f7705e1f25ff",
   "metadata": {},
   "source": [
    "## 4. TS-DTW with pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3513f3f-74b5-4f37-8fe6-3bc0e8f5de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time synchronous DTW with pruning\n",
    "def Pruning(input,templates,threshold):     \n",
    "    template_len=[0]\n",
    "    for i in range(10):\n",
    "        if i==0: template_len.append(np.shape(templates[i])[0])\n",
    "        else: template_len.append(template_len[-1]+np.shape(templates[i])[0])\n",
    "    # template_len = [0, 99, 168, 267, 366, 465, 564, 663, 762, 861, 960]\n",
    "    new_array=np.full(template_len[-1],np.inf)\n",
    "    old_array=np.full(template_len[-1],np.inf)\n",
    "    # i represents the number of vectors in the input\n",
    "    ranges=[[] for x in range(10)]\n",
    "    best=np.full(len(templates),np.inf)\n",
    "    for i in range(len(input)):\n",
    "        if i==0:\n",
    "            for k in range(len(template_len)-1): \n",
    "                cost=euclidean_distance(templates[k][0],input[i])\n",
    "                old_array[template_len[k]]=euclidean_distance(templates[k][0],input[i])\n",
    "                best[k]=cost\n",
    "                ranges[k].append(template_len[k]) \n",
    "            # print(ranges,best)\n",
    "        else:\n",
    "            for k in range(len(template_len)-1):\n",
    "                for y in range(len(ranges[k])):\n",
    "                    # prun out nodes that are greater than 1+threshold times the smallest distance in the old_array\n",
    "                    if old_array[ranges[k][y]]>best[k]*(1+threshold):\n",
    "                        old_array[ranges[k][y]]=np.inf\n",
    "                ranges[k]=[]\n",
    "                best[k]=np.inf\n",
    "                low=template_len[k]\n",
    "                high=template_len[k+1]\n",
    "                new_array[low]=old_array[low]+euclidean_distance(templates[k][0],input[i])\n",
    "                new_array[low+1]=min(old_array[low+1],old_array[low])+euclidean_distance(templates[k][1],input[i])\n",
    "                best[k]=min(new_array[low],new_array[low+1])\n",
    "                for j in range(low+2,high): \n",
    "                    cost=min(old_array[j-2],old_array[j-1],old_array[j])\n",
    "                    if cost==np.inf: \n",
    "                        new_array[j]=cost\n",
    "                    else: \n",
    "                        dist=euclidean_distance(templates[k][j-low],input[i])+cost\n",
    "                        new_array[j]=dist\n",
    "                        if dist<best[k]:\n",
    "                            best[k]=dist\n",
    "                        ranges[k].append(j)\n",
    "            old_array=new_array\n",
    "            new_array=np.full(template_len[-1],np.inf)            \n",
    "    type=0\n",
    "    dtw=old_array[template_len[1]-1]\n",
    "    for i in range(2,len(template_len)):\n",
    "        dist=old_array[template_len[i]-1]\n",
    "        if dist<dtw:\n",
    "            dtw=dist\n",
    "            type=i-1\n",
    "    return type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb0607-699a-452d-b6de-a8d6d87942b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get result matrix of TS_DTW with pruning\n",
    "def Pruning_recognition(templates,threshold):\n",
    "    result=np.zeros((len(templates),5))\n",
    "    for i in range(len(templates)):\n",
    "        for j in range(1,6):\n",
    "            training_feature=get_cepstrum_features('recorded_digits/'+str(i)+'_training_'+str(j)+'.wav')\n",
    "            type=Pruning(training_feature,templates,threshold)\n",
    "            result[i][j-1]=type\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ff20dc-2ee2-47cd-b519-a2f84718970c",
   "metadata": {},
   "source": [
    "## Accuracy of time synchronous DTW with pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d62695-842f-48d5-b7b3-de59c5819d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "a = np.arange(10).reshape(10, 1)\n",
    "correct_classifications = np.hstack((a,a,a,a,a))\n",
    "pruning_result=Pruning_recognition(template_feature_matrix,0.35)\n",
    "print(pruning_result)\n",
    "differing_positions = pruning_result != correct_classifications\n",
    "print('TS_DTW_with_Pruning Accuracy:',1-np.sum(differing_positions)/50)\n",
    "\n",
    "end_time = time.time()\n",
    "# Calculate the runtime\n",
    "runtime = end_time - start_time\n",
    "print(\"Runtime: {:.6f} seconds\".format(runtime))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934e1045-b247-4b88-be89-53f8cdb0e955",
   "metadata": {},
   "source": [
    "## Plot of different accuracy of pruning for different threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bd546a-3e43-4e2b-9a7b-50335cc48dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10).reshape(10, 1)\n",
    "correct_classifications = np.hstack((a,a,a,a,a))\n",
    "accuracy=[]\n",
    "for i in range(8):\n",
    "    pruning_result=Pruning_recognition(template_feature_matrix,0.05*i)\n",
    "    differing_positions = pruning_result != correct_classifications\n",
    "    accuracy.append(1-np.sum(differing_positions)/50)\n",
    "x = np.linspace(0.0,0.05*7,num=8)\n",
    "\n",
    "plt.plot(x, accuracy)\n",
    "\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f522596c-545f-4364-a3a7-ac70291dfa30",
   "metadata": {},
   "source": [
    "The best threshold is 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3259d1d4-ef4b-45e1-96bb-e0c110130879",
   "metadata": {},
   "source": [
    "## 5. Multiple template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6d9056-9149-4179-a7e9-a96b20d734b4",
   "metadata": {},
   "source": [
    "## Template Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6ba41b-7e0c-4fe6-9356-9d3ba3747f49",
   "metadata": {},
   "source": [
    "## Use DTW to align master template and other templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82d614-7222-4f6d-8f7d-55946d8c9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTW_template_averaging(input,template):      \n",
    "    previous_matrix=[[(-1,-1) for j in range(len(template))]for i in range(len(input))]\n",
    "    new_array=np.full(len(template),np.inf)\n",
    "    old_array=np.full(len(template),np.inf)\n",
    "    for i in range(len(input)):\n",
    "        if i==0:\n",
    "            old_array[0]=euclidean_distance(input[i],template[0])\n",
    "        else:\n",
    "            for j in range(len(template)):\n",
    "                if j==0:\n",
    "                    new_array[0]=old_array[0]+euclidean_distance(input[i], template[j])\n",
    "                    previous_matrix[i][j]=(i-1,0)\n",
    "                elif j==1:\n",
    "                    cost=min(old_array[j-1],old_array[j])\n",
    "                    if cost!=np.inf:\n",
    "                        if cost==old_array[j-1]: previous_matrix[i][j]=(i-1,j-1)\n",
    "                        else: previous_matrix[i][j]=(i-1,j)\n",
    "                    new_array[1]=euclidean_distance(input[i],template[j])+cost\n",
    "                else:\n",
    "                    cost=min(old_array[j-1],old_array[j-2],old_array[j])\n",
    "                    if cost!=np.inf:\n",
    "                        if cost==old_array[j-1]: previous_matrix[i][j]=(i-1,j-1)\n",
    "                        elif cost==old_array[j-2]: previous_matrix[i][j]=(i-1,j-2)\n",
    "                        else: previous_matrix[i][j]=(i-1,j)\n",
    "                    new_array[j]=euclidean_distance(input[i],template[j])+cost\n",
    "            old_array=new_array\n",
    "            new_array=np.full(len(template),np.inf)\n",
    "    path=[]\n",
    "    transition_type=[]\n",
    "    previous_point=previous_matrix[len(input)-1][len(template)-1]\n",
    "    \n",
    "    i=len(input)\n",
    "    if previous_point[1]==len(template)-1:\n",
    "        transition_type.append(0)\n",
    "    elif previous_point[1]==len(template)-2:\n",
    "        transition_type.append(1)\n",
    "    else:\n",
    "        transition_type.append(2) \n",
    "    while i>1 :\n",
    "        path.append(previous_point)\n",
    "        current=previous_point\n",
    "        previous_point=previous_matrix[previous_point[0]][previous_point[1]]\n",
    "        if current[1]==previous_point[1]:\n",
    "           transition_type.append(0)\n",
    "        elif current[1]==previous_point[1]+1:\n",
    "            transition_type.append(1)\n",
    "        else:\n",
    "            transition_type.append(2)\n",
    "        i-=1\n",
    "    # print(path)\n",
    "    return np.flip(transition_type[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43415e0-6826-439a-aaea-83c1388d35f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_type(index,num):\n",
    "    template=get_cepstrum_features(str(index)+'_template.wav')\n",
    "    type=[]\n",
    "    alignment=template\n",
    "    count=np.full(len(alignment),1)\n",
    "    for i in range(6,num+6):\n",
    "        input=get_cepstrum_features(str(index)+'_training_'+str(i)+'.wav')\n",
    "        curr_type=DTW_template_averaging(input,template)\n",
    "        type.append(curr_type)\n",
    "        # align the template and input by the trasition types\n",
    "        k=0\n",
    "        j=0\n",
    "        m=0\n",
    "        alignment[0]+=input[0]\n",
    "        count[0]+=1\n",
    "        while m<len(curr_type):\n",
    "            if curr_type[m]==1:\n",
    "                k+=1\n",
    "                j+=1\n",
    "            elif curr_type[m]==2:\n",
    "                j+=1\n",
    "                k+=2\n",
    "            else:\n",
    "                j+=1\n",
    "            alignment[k]+=input[j]\n",
    "            count[k]+=1\n",
    "            m+=1       \n",
    "    return alignment,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac4160e-856d-44a6-ac2a-0c7e7a607570",
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_template=[]\n",
    "for i in range(10):\n",
    "    alignment,count=get_transition_type(i,4)\n",
    "    count = count[:, np.newaxis]\n",
    "    averaged_template.append(alignment/count)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeeb991-e31f-4dfc-a0d3-d6ac754ecd90",
   "metadata": {},
   "source": [
    "## Test by DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129a1c25-f8f6-4b0e-a6b1-47a266b689a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the accuracy and runtime of the DTW\n",
    "start_time = time.time()\n",
    "\n",
    "a = np.arange(10).reshape(10, 1)\n",
    "correct_classifications = np.hstack((a,a,a,a,a))\n",
    "dtw_result=DTW_recognition(averaged_template)\n",
    "print(dtw_result)\n",
    "differing_positions = dtw_result != correct_classifications\n",
    "print('DTW Accuracy:',1-np.sum(differing_positions)/50)\n",
    "\n",
    "end_time = time.time()\n",
    "# Calculate the runtime\n",
    "runtime = end_time - start_time\n",
    "print(\"Runtime: {:.6f} seconds\".format(runtime))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ec6e7b-061e-4b87-9af7-48f37d8340fa",
   "metadata": {},
   "source": [
    "## Test by Time Synchronous DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee49b30-d7b0-41e5-9d8b-0bd7a510e24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "a = np.arange(10).reshape(10, 1)\n",
    "correct_classifications = np.hstack((a,a,a,a,a))\n",
    "ts_dtw_result=TS_DTW_recognition(averaged_template)\n",
    "print(ts_dtw_result)\n",
    "differing_positions = ts_dtw_result != correct_classifications\n",
    "print('TS_DTW Accuracy:',1-np.sum(differing_positions)/50)\n",
    "\n",
    "end_time = time.time()\n",
    "# Calculate the runtime\n",
    "runtime = end_time - start_time\n",
    "print(\"Runtime: {:.6f} seconds\".format(runtime))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec283df-38f4-4e89-8ed9-8aeeb6544b9c",
   "metadata": {},
   "source": [
    "## Test by pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04ce70-5141-4ccc-a396-31ba5abdacf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "a = np.arange(10).reshape(10, 1)\n",
    "correct_classifications = np.hstack((a,a,a,a,a))\n",
    "pruning_result=Pruning_recognition(averaged_template,0.3)\n",
    "print(pruning_result)\n",
    "differing_positions = pruning_result != correct_classifications\n",
    "print('TS_DTW_with_Pruning Accuracy:',1-np.sum(differing_positions)/50)\n",
    "\n",
    "end_time = time.time()\n",
    "# Calculate the runtime\n",
    "runtime = end_time - start_time\n",
    "print(\"Runtime: {:.6f} seconds\".format(runtime))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9add83c1-8a7e-41d2-8df9-04c01b93d143",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10056a8a-cf5b-495c-9e9b-e8292c89ff54",
   "metadata": {},
   "source": [
    "## Training an HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507b7e84-9767-4678-ba2b-f1de0df3bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative log Gaussian\n",
    "def log_Gaussian(m, sigma_square, x):\n",
    "    left=0.5*np.sum(np.log(2*np.pi*sigma_square))\n",
    "    right=0.5*np.sum(np.square((x-m))/sigma_square)\n",
    "    return left+right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c2ed05-80e7-4a34-96ae-f9f293ad3aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_states(D):\n",
    "    #start from the last state and last frame\n",
    "    current_state,current_frame=np.array(D.shape)-1\n",
    "    #insert the last frame's state\n",
    "    x=[current_state]\n",
    "    # we do not need the frame 0, which is the fine\n",
    "    while current_state>0 and current_frame>1:\n",
    "        #move to the previous frame\n",
    "        current_frame-=1\n",
    "        if current_state>2:\n",
    "            to_check=[D[current_state][current_frame-1],\n",
    "                      D[current_state-1][current_frame-1],\n",
    "                      D[current_state-2][current_frame-1]]\n",
    "            track=np.argmin(to_check)\n",
    "        elif current_state>1:\n",
    "            to_check=[D[current_state][current_frame-1],\n",
    "                      D[current_state-1][current_frame-1]]\n",
    "            track=np.argmin(to_check)\n",
    "        else:\n",
    "            track=0\n",
    "            \n",
    "        if track==0:\n",
    "            x.insert(0,current_state)\n",
    "        elif track==1:\n",
    "            current_state-=1\n",
    "            x.insert(0,current_state)\n",
    "        else:\n",
    "            current_state-=2\n",
    "            x.insert(0,current_state)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2abe38b-5bb5-4241-81e3-38eedcc1e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HMM_DTW(mean,data,state,T,covariance):\n",
    "    mean=np.vstack([np.zeros(len(data[0])),mean])\n",
    "    covariance=np.vstack([np.full(len(data[0]),1),covariance])\n",
    "    data=np.vstack([np.zeros(len(data[0])),data])\n",
    "    state+=1\n",
    "    previous=[[(-1,-1) for i in range(len(data))] for j in range(state)]\n",
    "    P=np.zeros((state,len(data)))\n",
    "    for j in range(len(data)):\n",
    "        for i in range(state):\n",
    "            node_cost=log_Gaussian(mean[i],covariance[i],data[j])\n",
    "            if i>=2:\n",
    "                minimum=min(P[i][j-1]+T[i][i],P[i-1][j-1]+T[i-1][i],P[i-2][j-1]+T[i-2][i])\n",
    "                P[i][j]=minimum+node_cost\n",
    "            elif i>=1:\n",
    "                minimum=min(P[i][j-1]+T[i][i],P[i-1][j-1]+T[i-1][i])\n",
    "                P[i][j]=min(P[i][j-1]+T[i][i],P[i-1][j-1]+T[i-1][i])+node_cost\n",
    "            else:\n",
    "                P[i][j]=P[i][j-1]+node_cost\n",
    "    P=P/len(data)\n",
    "    dist=P[-1][-1]\n",
    "    states=get_states(P)\n",
    "    return dist,states  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158f602a-2bac-4016-9f43-9724c001c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_boundary(data,state=5):\n",
    "    states=[]\n",
    "    for i in range(len(data)):\n",
    "        length=len(data[i])//5\n",
    "        remainder=len(data[i])%5\n",
    "        curr_state=np.zeros(len(data[i])).astype(int)   \n",
    "        for i in range(1,state+1):\n",
    "            curr_state[length*(i-1):length*i]=int(i)\n",
    "        if remainder!=0:\n",
    "            curr_state[-remainder:]=int(state)\n",
    "        states.append(curr_state)       \n",
    "    return states\n",
    "    # calculate state means and covarriances \n",
    "def MeanAndVar(data,states,state=5):\n",
    "    means=[]\n",
    "    covs=[]\n",
    "    nodes=[[] for i in range(state+1)]#record nodes in different states\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(states[i])):\n",
    "            nodes[states[i][j]].append(data[i][j])\n",
    "    for i in range(1,state+1):\n",
    "        mean=np.mean(nodes[i],0)\n",
    "        means.append(mean)\n",
    "        node=np.array(nodes[i])\n",
    "        cov=np.cov(np.array(node).T)\n",
    "        cov=np.diagonal(cov, offset=0, axis1=0, axis2=1)\n",
    "        covs.append(cov)\n",
    "    return means,covs\n",
    "        \n",
    "def TransitionScore(states,state=5):\n",
    "    score=np.full((state+1,state+1),np.inf)\n",
    "    num_nodes_in_state=np.zeros(state+1)\n",
    "    for i in range(len(states)):\n",
    "        for j in range(len(states[i])):\n",
    "            num_nodes_in_state[states[i][j]]+=1\n",
    "    for i in range(1,state+1):\n",
    "        for j in range(state+1):\n",
    "            if i==j: score[i][j]=-np.log((num_nodes_in_state[i]-state)/num_nodes_in_state[i])\n",
    "            elif i==j-1: score[i][j]=-np.log(state/num_nodes_in_state[i])\n",
    "    score[0][1]=0\n",
    "    score[state][state]=0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35056c8d-4633-4d96-987f-12537f89542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Training_HMM(data,state=5):\n",
    "    # initialize boundary matrix\n",
    "    states=initialize_boundary(data)\n",
    "    # mean and covariance for the initial state segment\n",
    "    mean,cov=MeanAndVar(data,states)\n",
    "    \n",
    "    # calculate transition score\n",
    "    score=TransitionScore(states)\n",
    "    best_distance=-np.inf\n",
    "    for i in range(1,100):\n",
    "        curr_dist=0\n",
    "        for j in range(len(data)):\n",
    "            distance,states[j]=HMM_DTW(mean,data[j],5,score,cov)\n",
    "            curr_dist+=distance\n",
    "        # mean and covariance for the initial state segment\n",
    "        mean,cov=MeanAndVar(data,states)\n",
    "        # calculate transition score\n",
    "        score=TransitionScore(states)\n",
    "        # do DTW to get new state segment\n",
    "        improvement=best_distance-curr_dist\n",
    "        best_distance=curr_dist\n",
    "        # print(improvement)\n",
    "        if abs(improvement)<0.0015:\n",
    "            # print(\"Number of iterations:\",i)\n",
    "            break\n",
    "    return mean, cov, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59de73-b03d-415b-ae7c-8e8dbfbec718",
   "metadata": {},
   "outputs": [],
   "source": [
    "means=[]\n",
    "covariances=[]\n",
    "scores=[]\n",
    "for j in range(10):\n",
    "    data=[]\n",
    "    data.append(get_cepstrum_features('recorded_digits/'+str(j)+'_template.wav'))\n",
    "    for i in range(1,5):\n",
    "        data.append(get_cepstrum_features('recorded_digits/'+str(j)+'_training_'+str(i)+'.wav'))\n",
    "    mean,cov,score=Training_HMM(data)\n",
    "    means.append(mean)\n",
    "    covariances.append(cov)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff777ea-1251-4ff1-b36e-42c3d5e123f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in range(10):\n",
    "    for j in range(5,10):\n",
    "        best_dist=np.inf\n",
    "        test_data=get_cepstrum_features('recorded_digits/'+str(i)+'_training_'+str(j)+'.wav')\n",
    "        type=-1\n",
    "        for k in range(10):\n",
    "            dist,state=HMM_DTW(means[k],test_data,5,scores[k],covariances[k])\n",
    "            if min(dist,best_dist)==dist:\n",
    "                best_dist=dist\n",
    "                type=k\n",
    "        if type!=i: count+=1\n",
    "print('Accuracy:',1-count/50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed32fb1-97d9-44af-9265-db08088dc59a",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5d7ba3-983d-4be6-8eba-afff0d1ae77f",
   "metadata": {},
   "source": [
    "## HMM with Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c460137-a366-42ed-af72-fcf0a6fd1c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Gaussian_mean =[]\n",
    "Gaussian_var =[]\n",
    "Gaussian_weight =[]\n",
    "Gaussian_total=[Gaussian_mean,Gaussian_var,Gaussian_weight]\n",
    "Num_of_Gaussian = 0\n",
    "initial_matrix=[]\n",
    "transition_cost =[]\n",
    "state_mix =[]\n",
    "state_number = 0 \n",
    "\n",
    "def gaussian(data,sigma_square,ftheta):\n",
    "    #likelihoods\n",
    "    sigma_square_producted=np.prod(sigma_square,axis=1)\n",
    "    p=(1/(np.sqrt((2*np.pi)**2 *sigma_square)))*(np.exp(-0.5*np.sum((data-ftheta)**2/sigma_square_producted,axis=1)))\n",
    "    return p\n",
    "\n",
    "def log_gaussian(data,sigma_square,ftheta):\n",
    "    cost= 0.5*np.sum(np.log((2*np.pi)*(sigma_square)),axis=1)+0.5*np.sum(np.square((ftheta-data))/sigma_square,axis=1)\n",
    "    return cost\n",
    "\n",
    "def mix_log_gaussian(Gaussian_total,ftheta):\n",
    "    Gaussian_mean=Gaussian_total[0]\n",
    "    Gaussian_var=Gaussian_total[1]\n",
    "    Gaussian_weight=Gaussian_total[2]\n",
    "    cost=log_gaussian(Gaussian_mean,Gaussian_var,ftheta)\n",
    "    changed_cost=np.sum(Gaussian_weight*cost)\n",
    "    return changed_cost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
