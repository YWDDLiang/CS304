{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c74220a5-f9ae-4a37-8cbd-8ab9b19e1cbe",
   "metadata": {},
   "source": [
    "# GMMHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8dd8841-519b-491e-bf5a-fc1102105501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6a2dbb0-cebe-4c26-b892-84b0d478eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixture model class\n",
    "class GMMInfo:\n",
    "    def __init__(self):\n",
    "        self.weight=[] #gmm weight\n",
    "        self.mean=[] #gmm mean\n",
    "        self.var=[] # gmm diagonal covariance\n",
    "        self.num=0 # number of gmms\n",
    "# hmm class\n",
    "class HMMInfo:\n",
    "    def __init__(self):\n",
    "        self.init=[]\n",
    "        self.edge_cost=[]\n",
    "        self.mix=[]\n",
    "        self.num=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b80f9ea5-0800-4096-bfdd-15e5d9e3275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_Gaussian(m,C,x):\n",
    "    left=0.5*np.sum(np.log((2*np.pi)*C),axis=1)\n",
    "    right=0.5*np.sum(np.square((x-m))/C,axis=1)\n",
    "    return left+right\n",
    "\n",
    "def mixture_log_Gaussian(mix,x):\n",
    "    mu=mix.mean\n",
    "    var=mix.var\n",
    "    w=mix.weight\n",
    "    cost=log_Gaussian(mu,var,x)\n",
    "    # print(w,cost)\n",
    "    w=np.array(w)\n",
    "    total_cost=np.sum(w*cost)\n",
    "    return total_cost\n",
    "\n",
    "def Gaussian(m,C,x):\n",
    "    part1=np.sqrt((2*np.pi)**2*np.prod(C,axis=1))\n",
    "    part2=0.5*np.sum(np.square(x-m)/C,axis=1)\n",
    "    prob=(1/part1)*np.exp(-part2)\n",
    "    return prob\n",
    "\n",
    "\n",
    "def mix_Gaussian(mix,x):\n",
    "    m=mix.mean\n",
    "    var=mix.var\n",
    "    w=mix.weight\n",
    "    prob=log_Gaussian(m,var,x)\n",
    "    total_prob=np.sum(w*prob)\n",
    "    return total_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a945fde0-a917-477f-a2b6-b8dc0f4f8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMMHMM_DTW(HMM,data):\n",
    "    # matrix that records the edge costs\n",
    "    T=HMM.edge_cost\n",
    "    zeros=np.zeros([39])\n",
    "    ones=np.zeros([39])+1\n",
    "    mixture_models=[]\n",
    "    #create a GMM for the initial state\n",
    "    init_GMM=GMMInfo()\n",
    "    init_GMM.weight=[1]\n",
    "    init_GMM.num=1\n",
    "    init_GMM.mean.append(zeros)\n",
    "    init_GMM.var.append(ones)\n",
    "    init_GMM.mean=np.array(init_GMM.mean)\n",
    "    init_GMM.var=np.array(init_GMM.var)\n",
    "    mixture_models.append(init_GMM)\n",
    "    for mix_model in HMM.mix:\n",
    "        mixture_models.append(mix_model)\n",
    "    data=np.vstack([zeros,data])\n",
    "    s=len(data)\n",
    "    t=len(mixture_models)\n",
    "    #Matrix that stores the costs\n",
    "    P=np.zeros([t,s])\n",
    "    #dynamic time programming algo\n",
    "    for j in range(0,s):\n",
    "        for i in range(t):\n",
    "            #node score\n",
    "            # print((i,j))\n",
    "            Cij=mixture_log_Gaussian(mixture_models[i],data[j])\n",
    "            \n",
    "                \n",
    "            if i>=2:\n",
    "                P[i][j]=min(P[i][j-1]+T[i][i],P[i-1][j-1]+T[i-1][i],\n",
    "                            P[i-2][j-1]+T[i-2][i])+Cij\n",
    "            elif i-1>=0:\n",
    "                P[i][j]=min(P[i][j-1]+T[i][i],P[i-1][j-1]+T[i-1][i])+Cij\n",
    "            else:\n",
    "                P[i][j]=P[i][j]+Cij\n",
    "    P=P/s\n",
    "    total_cost=P[-1][-1]\n",
    "    return total_cost,get_states(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217d43dd-ab81-4723-b060-ff7b3f972bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list that records which state each frame belongs to\n",
    "def get_states(P):\n",
    "    current_state,current_frame=np.array(P.shape)-1\n",
    "    states=[current_state]\n",
    "    while current_state>0 and current_frame>1:\n",
    "      \n",
    "      current_frame-=1\n",
    "      if current_state>2:\n",
    "          to_check=[P[current_state][current_frame-1],P[current_state-1][current_frame-1],P[current_state-2][current_frame-1]]\n",
    "          track=np.argmin(to_check)\n",
    "      elif current_state>1:\n",
    "          to_check=[P[current_state][current_frame-1],P[current_state-1][current_frame-1]]\n",
    "          track=np.argmin(to_check)\n",
    "      else:\n",
    "          track=0\n",
    "      if track==0:\n",
    "          states.insert(0,current_state)\n",
    "      elif track==1:\n",
    "          current_state-=1\n",
    "          states.insert(0,current_state)\n",
    "      else:\n",
    "          current_state-=2\n",
    "          states.insert(0,current_state)\n",
    "    return states\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ac61321-ffe8-4b61-b059-146ece22c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_templates(templates, num):\n",
    "    states_info=[]\n",
    "    for i in range(len(templates)):\n",
    "        # For the ith template, the number of nodes in each state is initialized evenly\n",
    "        nodes_num=len(templates[i])//num\n",
    "        remaining_nodes=len(templates[i])%num\n",
    "        curr_states_info=np.zeros(len(templates[i])).astype(int)\n",
    "        for state in range(1,num+1):\n",
    "            curr_states_info[nodes_num*(state-1):nodes_num*state]=state\n",
    "        if remaining_nodes>0:\n",
    "            curr_states_info[-remaining_nodes:]=num\n",
    "        states_info.append(curr_states_info)\n",
    "    return states_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cfb715b-526f-465f-a6f3-574dd35531ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_in_each_state(templates, state_num, states_info):\n",
    "    node_in_each_state=[]\n",
    "    for state in range(state_num+1):\n",
    "        node_in_each_state.append([])\n",
    "    for j in range(len(templates)):\n",
    "        # print('len:',len(states_info[j]))\n",
    "        for m in range(len(states_info[j])):\n",
    "            k=int(states_info[j][m])\n",
    "            node_in_each_state[k].append(templates[j][m])\n",
    "    return node_in_each_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87b0a761-a6ed-4901-93f8-9e962e3e33c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_cost(states_info,state_num):\n",
    "\n",
    "    shift_prob=np.zeros((state_num+1,state_num+1))\n",
    "    num_nodes_in_state=np.zeros(state_num+1)\n",
    "    for i in range(len(states_info)):\n",
    "        shift_prob[0][states_info[i][0]]+=1\n",
    "    # count the state trainsition\n",
    "    for i in range(len(states_info)):\n",
    "        for j in range(len(states_info[i])-1):\n",
    "            current_node=states_info[i][j]\n",
    "            next_node=states_info[i][j+1]\n",
    "            shift_prob[current_node][next_node]+=1\n",
    "            num_nodes_in_state[current_node]+=1\n",
    "        shift_prob[states_info[i][-2]][states_info[i][-1]]+=1\n",
    "        num_nodes_in_state[states_info[i][-1]]+=1\n",
    "    # get the probabilities of going from initial state to 1~state_num states \n",
    "    for j in range(state_num+1):\n",
    "        N=len(states_info)\n",
    "        N_0j=shift_prob[0][j]\n",
    "        shift_prob[0][j]=N_0j/N\n",
    "        if N_0j==0:\n",
    "            shift_prob[0][j]=np.inf\n",
    "        else:\n",
    "            shift_prob[0][j]=-np.log(shift_prob[0][j])\n",
    "    for i in range(1,state_num+1):\n",
    "        for j in range(i,state_num+1):\n",
    "            \n",
    "            shift_prob[i][j]=shift_prob[i][j]/num_nodes_in_state[i]\n",
    "            if shift_prob[i][j]==0:\n",
    "                shift_prob[i][j]=np.inf\n",
    "            else:\n",
    "                shift_prob[i][j]=-np.log(shift_prob[i][j])\n",
    "    return np.array(shift_prob)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfae7d9a-0f65-4e72-8d27-ddea63c695d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kmeans2(nodes_for_Kmeans,num_Gaussian_distribution):\n",
    "        #initialize with mean, var and weight, with one cluster\n",
    "        num_templates=len(nodes_for_Kmeans)\n",
    "        means=[]\n",
    "        covs=[]\n",
    "        weights=[1]\n",
    "        mean=np.mean(nodes_for_Kmeans,axis=0)\n",
    "        cov=np.diagonal(np.cov(np.array(nodes_for_Kmeans).T),offset=0, axis1=0, axis2=1)\n",
    "        means.append(mean)\n",
    "        covs.append(cov)\n",
    "        \n",
    "        current_num_of_cluster=1\n",
    "        episolom=0.04\n",
    "        #initial should be 1 mean\n",
    "        mix = GMMInfo()\n",
    "        mix.var = np.array(covs)\n",
    "        mix.mean = np.array(means)\n",
    "        mix.num = current_num_of_cluster\n",
    "        mix.weight = np.array(weights)\n",
    "        stop=False\n",
    "        \n",
    "        while num_Gaussian_distribution>current_num_of_cluster and not stop:\n",
    "            #now split\n",
    "            new_means=[]\n",
    "            new_covs=[]\n",
    "            current_num_of_cluster=current_num_of_cluster*2\n",
    "            new_clusters=[]\n",
    "            for cluster in range(len(means)):\n",
    "                #append newly two cluster center\n",
    "                new_clusters.append([])\n",
    "                new_clusters.append([])\n",
    "                #get splitted mean and cov\n",
    "                new_mean1=means[cluster]*(1-episolom)\n",
    "                new_mean2=means[cluster]*(1+episolom)\n",
    "                new_cov1=covs[cluster]*(1-episolom)\n",
    "                new_cov2=covs[cluster]*(1+episolom)\n",
    "                new_means.append(new_mean1)\n",
    "                new_means.append(new_mean2)\n",
    "                new_covs.append(new_cov1)\n",
    "                new_covs.append(new_cov2)\n",
    "            #now assign the templated into new clusters\n",
    "            new_means=np.array(new_means)\n",
    "            new_covs=np.array(new_covs)\n",
    "            for node in nodes_for_Kmeans:\n",
    "                d=log_Gaussian(new_means,new_covs,node)\n",
    "                cluster=np.argmin(d)\n",
    "                new_clusters[cluster].append(node)\n",
    "            #now, according to the new clustered result, we get updated weight,\n",
    "            #mean and cov\n",
    "            means=[]\n",
    "            covs=[]\n",
    "            weights=[]\n",
    "            #\n",
    "            # print(\"For {} clusters, each cluster has following nodes\".format(current_num_of_cluster))\n",
    "            for cluster in new_clusters:\n",
    "                # print(len(cluster))\n",
    "                if len(cluster)<2*num_Gaussian_distribution:\n",
    "                    stop=True\n",
    "                    # print(\"For this state, we only have 2 Gaussian Distributions\")\n",
    "                mean=np.mean(cluster,axis=0)\n",
    "                cov=np.cov(np.array(cluster).T)\n",
    "                # print(np.shape(cov))\n",
    "                cov=np.diagonal(cov,offset=0, axis1=0, axis2=1)\n",
    "                weight=len(cluster)/num_templates\n",
    "                means.append(mean)\n",
    "                covs.append(cov)\n",
    "                weights.append(weight)\n",
    "            #print(np.sum(weights))\n",
    "            # print(\"get {} means\".format(current_num_of_cluster))\n",
    "            # now, we put all the information to mix\n",
    "            mix = GMMInfo()\n",
    "            mix.var = np.array(covs)\n",
    "            mix.mean = np.array(means)\n",
    "            mix.num = current_num_of_cluster\n",
    "            mix.weight = np.array(weights)\n",
    "        return mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37b82238-1c69-44bf-9fb0-019c1edc801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_HMM(templates, state_num, Gaussian_num):\n",
    "    hmm=HMMInfo()\n",
    "    hmm.init=np.zeros((state_num,1))\n",
    "    hmm.init[0]=1\n",
    "    hmm.num=state_num\n",
    "\n",
    "    states_info=seperate_templates(templates, state_num)\n",
    "    node_in_each_state=get_node_in_each_state(templates, state_num, states_info)\n",
    "    hmm.edge_cost=get_edge_cost(states_info,state_num)\n",
    "    \n",
    "    mix_models=[]\n",
    "    for i in range(state_num):\n",
    "        node_in_curr_state=node_in_each_state[i+1]\n",
    "        curr_state_mix_model=Kmeans2(node_in_curr_state, Gaussian_num[i])\n",
    "        mix_models.append(curr_state_mix_model)\n",
    "    hmm.mix=mix_models\n",
    "    \n",
    "    return hmm,states_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "060f7884-6093-476c-a616-4cd52c22e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train hmm model\n",
    "def trainhmm(templates,state_num,Gaussian_num):\n",
    "    #initialize hmm model\n",
    "    hmm,states_info=initialize_HMM(templates,state_num,Gaussian_num)\n",
    "    best_dist=-np.inf\n",
    "    curr_dist=0\n",
    "    length=0\n",
    "    # use at most 99 iterations to train the model\n",
    "    for i in range(1,100):\n",
    "        for j in range(len(templates)):\n",
    "            # use dtw to get the score and update alignment of the templates\n",
    "            dist,states_info[j]=GMMHMM_DTW(hmm,templates[j])\n",
    "            \n",
    "            curr_dist+=dist\n",
    "        hmm.edge_cost=get_edge_cost(states_info,state_num)\n",
    "        # according to the alignment, classify the vectors of templates into different states\n",
    "        node_in_each_state=get_node_in_each_state(templates,state_num,states_info)\n",
    "        GMMs=[]\n",
    "        for state in range(state_num):\n",
    "            curr_state_node=node_in_each_state[state+1]\n",
    "            # kmeans these vectors into 4 clusters to get weight, mean, var\n",
    "            # print(curr_state_node)\n",
    "            curr_mixture=Kmeans2(curr_state_node,Gaussian_num[state])\n",
    "            GMMs.append(curr_mixture)\n",
    "        hmm.mix=GMMs\n",
    "        # if it converges, break the iteration\n",
    "        if abs(best_dist-curr_dist)<0.0015:\n",
    "            length=len(node_in_each_state[state_num])\n",
    "            break\n",
    "        # update the best score\n",
    "        best_dist=curr_dist\n",
    "        # print(best_dist)\n",
    "        curr_dist=0\n",
    "\n",
    "    # Here we get the number of nodes in the last state and calculate the \n",
    "    # probability of going to the non-emitting state from the last state.\n",
    "    new_edge_cost=np.zeros((state_num+1,state_num+2))\n",
    "    num_nodes_at_last_state=length\n",
    "    template_num=len(templates)\n",
    "    non_emitting_state_prob=template_num/num_nodes_at_last_state\n",
    "    log_prob=np.log(non_emitting_state_prob)\n",
    "    # print(hmm.edge_cost,new_edge_cost)\n",
    "    new_edge_cost[:state_num+1,:state_num+1]=hmm.edge_cost\n",
    "    new_edge_cost[state_num][state_num+1]=log_prob\n",
    "    hmm.edge_cost=new_edge_cost\n",
    "    return hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca80b5fc-c3e5-4db6-ba81-aa8f3e79008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get MFCC of length 39\n",
    "def getMFCC(wavename):\n",
    "    import numpy as np\n",
    "    import scipy.io.wavfile as wav\n",
    "    from python_speech_features import mfcc\n",
    "    fs, audio = wav.read(wavename)\n",
    "    feature_mfcc = mfcc(audio, samplerate=fs)\n",
    "    mfcc=[]\n",
    "    mfcc.append(np.hstack([feature_mfcc[0],feature_mfcc[0],feature_mfcc[0]]))\n",
    "    for i in range(1,len(feature_mfcc)-1):\n",
    "        delta=np.zeros(13)\n",
    "        for j in range(13):\n",
    "            delta[j]=feature_mfcc[i+1][j]-feature_mfcc[i-1][j]\n",
    "        mfcc.append(np.hstack([feature_mfcc[i],delta]))\n",
    "    mfcc.append(np.hstack([feature_mfcc[-1],feature_mfcc[-1],feature_mfcc[-1]]))\n",
    "\n",
    "    for i in range(1,len(mfcc)-1):\n",
    "        acc=np.zeros(13)\n",
    "        for j in range(13):\n",
    "            acc[j]=mfcc[i+1][13+j]-mfcc[i-1][13+j]\n",
    "        mfcc[i]=np.hstack([mfcc[i],acc])\n",
    "    mfccs=np.array(mfcc)\n",
    "    std=np.std(mfccs)\n",
    "    var=np.var(mfccs,1)\n",
    "    for i in range(len(mfccs)):\n",
    "        for j in range(39):\n",
    "            mfccs[i][j]=mfccs[i][j]/var[i]\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a8680faa-be00-49ff-b5cb-093748e2d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMMHMM(folder,Gaussian_num,words):\n",
    "    models=[]\n",
    "    for word in words:\n",
    "        templates=[]\n",
    "        \n",
    "        \n",
    "        state_num=len(Gaussian_num)\n",
    "        # 5 templates\n",
    "        for i in range(1,6):\n",
    "            mfcc=getMFCC(folder+'/'+str(word)+''+str(i)+'.wav')\n",
    "            templates.append(mfcc)\n",
    "        # call trainhmm function to get the hmm model for each digit\n",
    "        hmm=trainhmm(templates,state_num,Gaussian_num)\n",
    "        models.append(hmm)\n",
    "        print('hmm model '+str(word)+' trained')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f45b5e8a-f392-4e4e-9bf0-e7e538e47977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmm model 0 trained\n",
      "hmm model 1 trained\n",
      "hmm model 2 trained\n",
      "hmm model 3 trained\n",
      "hmm model 4 trained\n",
      "hmm model 5 trained\n",
      "hmm model 6 trained\n",
      "hmm model 7 trained\n",
      "hmm model 8 trained\n",
      "hmm model 9 trained\n"
     ]
    }
   ],
   "source": [
    "folder='digit_record_new'\n",
    "Gaussian_num=[2,2,2,2]\n",
    "words=[i for i in range(10)]\n",
    "gmmhmm_model=GMMHMM(folder,Gaussian_num,words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5d882ea-6549-46d3-ad10-7650aab6b2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_models={}\n",
    "for i in range(len(gmmhmm_model)):\n",
    "    hmm_models[str(i)]=gmmhmm_model[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf9767-b954-4e60-89dd-33b1db9c11d2",
   "metadata": {},
   "source": [
    "## Accuracy of single digit recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8c0d9a1-6d2d-4add-944a-f8c34e33ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_templates(foldername,i,j):\n",
    "    templates=[]\n",
    "    for num in range(i,j):\n",
    "        for digit in range(0,10):\n",
    "            mfcc=getMFCC(foldername+\"/\"+str(digit)+str(num)+'.wav')\n",
    "            templates.append(mfcc)\n",
    "    return templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c744670-cc0d-41b3-9aeb-ed8da0982da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGMM_HMM_accuracy(gmmhmm_model,data):\n",
    "    accuracy=0\n",
    "    for j in range(len(data)):\n",
    "        current_digit=j%10\n",
    "        smallest_distance=[np.inf,0]\n",
    "        for i in range(10):\n",
    "            distance=GMMHMM_DTW(gmmhmm_model[i],data[j])\n",
    "            if distance[0]<smallest_distance[0]:\n",
    "                smallest_distance[0]=distance[0]\n",
    "                smallest_distance[1]=i\n",
    "        recoginized_result=smallest_distance[1]\n",
    "        if current_digit==recoginized_result:\n",
    "            accuracy+=1\n",
    "        print('test data: '+str(current_digit)+', recognized digit:',recoginized_result)\n",
    "    print('accuracy:',accuracy/len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7f8d3dc-87db-4cc2-8c17-305a8ddb1c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername='digit_record_test'\n",
    "test_data=get_templates(foldername,1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "470c1a93-86fd-4cdf-9c3b-1043da7d8009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data: 0, recognized digit: 0\n",
      "test data: 1, recognized digit: 9\n",
      "test data: 2, recognized digit: 2\n",
      "test data: 3, recognized digit: 3\n",
      "test data: 4, recognized digit: 4\n",
      "test data: 5, recognized digit: 5\n",
      "test data: 6, recognized digit: 0\n",
      "test data: 7, recognized digit: 7\n",
      "test data: 8, recognized digit: 8\n",
      "test data: 9, recognized digit: 9\n",
      "test data: 0, recognized digit: 0\n",
      "test data: 1, recognized digit: 9\n",
      "test data: 2, recognized digit: 2\n",
      "test data: 3, recognized digit: 3\n",
      "test data: 4, recognized digit: 4\n",
      "test data: 5, recognized digit: 9\n",
      "test data: 6, recognized digit: 6\n",
      "test data: 7, recognized digit: 7\n",
      "test data: 8, recognized digit: 8\n",
      "test data: 9, recognized digit: 9\n",
      "test data: 0, recognized digit: 0\n",
      "test data: 1, recognized digit: 9\n",
      "test data: 2, recognized digit: 2\n",
      "test data: 3, recognized digit: 3\n",
      "test data: 4, recognized digit: 4\n",
      "test data: 5, recognized digit: 9\n",
      "test data: 6, recognized digit: 6\n",
      "test data: 7, recognized digit: 7\n",
      "test data: 8, recognized digit: 8\n",
      "test data: 9, recognized digit: 9\n",
      "test data: 0, recognized digit: 0\n",
      "test data: 1, recognized digit: 9\n",
      "test data: 2, recognized digit: 2\n",
      "test data: 3, recognized digit: 3\n",
      "test data: 4, recognized digit: 4\n",
      "test data: 5, recognized digit: 5\n",
      "test data: 6, recognized digit: 6\n",
      "test data: 7, recognized digit: 7\n",
      "test data: 8, recognized digit: 8\n",
      "test data: 9, recognized digit: 9\n",
      "test data: 0, recognized digit: 0\n",
      "test data: 1, recognized digit: 1\n",
      "test data: 2, recognized digit: 2\n",
      "test data: 3, recognized digit: 3\n",
      "test data: 4, recognized digit: 4\n",
      "test data: 5, recognized digit: 5\n",
      "test data: 6, recognized digit: 6\n",
      "test data: 7, recognized digit: 7\n",
      "test data: 8, recognized digit: 8\n",
      "test data: 9, recognized digit: 9\n",
      "accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "getGMM_HMM_accuracy(gmmhmm_model,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999b5843-daee-44cf-b9ae-8b3eb8268a3a",
   "metadata": {},
   "source": [
    "# Continuous Speech Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ad860a-7edb-45b6-9a7b-1d6aecda93ab",
   "metadata": {},
   "source": [
    "## Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23bb1c80-de36-4fd7-a254-6baa63717684",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,val, word):\n",
    "        self.val=val\n",
    "        self.next=[]\n",
    "        self.word=word\n",
    "        #three states: -1: root, 1: end, 0: others\n",
    "        self.state=0        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c1d611-ad6d-4ef8-87e6-d09bf7782a12",
   "metadata": {},
   "source": [
    "## Lexical Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5e2fc21-0c17-4cb2-ad59-d3708842848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LexicalTree:\n",
    "    def __init__(self,models):\n",
    "        self.getwords(models)\n",
    "        zeros=np.zeros([39])\n",
    "        ones=np.array([1 for i in range(39)])\n",
    "        # set the initial state as a Gaussian mixture model\n",
    "        initial_GMM=GMMInfo()\n",
    "        initial_GMM.mean.append(zeros)\n",
    "        initial_GMM.var.append(ones)\n",
    "        initial_GMM.mean=np.array(initial_GMM.mean)\n",
    "        initial_GMM.var=np.array(initial_GMM.var)\n",
    "        initial_GMM.weight=[1]\n",
    "        initial_GMM.num=1\n",
    "        # let the initial state as the root of the lexical tree\n",
    "        self.root=Node(initial_GMM,'*')\n",
    "        self.root.state=-1\n",
    "           \n",
    "    # get model and transition cost for each digits\n",
    "    def getwords(self,models):\n",
    "        self.words=[]\n",
    "        self.digits=list(models.keys())\n",
    "        self.edge_cost={}\n",
    "        for digit in self.digits:\n",
    "            self.words.append(models[digit])\n",
    "            self.edge_cost[digit]=models[digit].edge_cost\n",
    "\n",
    "    def GenerateTree(self):\n",
    "        for i in range(len(self.words)):\n",
    "            word=self.words[i]\n",
    "            digit=self.digits[i]\n",
    "            # the initial state for ith digit\n",
    "            previous=Node(word.mix[0],digit)\n",
    "            # which is one of the next option for the root node\n",
    "            self.root.next.append(previous)\n",
    "            # other states for the digit\n",
    "            for j in range(1,word.num):\n",
    "                curr=Node(word.mix[j],digit)\n",
    "                previous.next.append(curr)\n",
    "                previous=curr\n",
    "            # for the last state for the ith digit, its next node is root\n",
    "            previous.next.append(self.root)\n",
    "            previous.state=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4949008e-31c6-4f61-ac9b-834e82716bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lextree=LexicalTree(hmm_models)\n",
    "lextree.GenerateTree()\n",
    "root=lextree.root\n",
    "edge_cost=lextree.edge_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd60f31-7c66-4e3b-961f-4f49e4fa2da6",
   "metadata": {},
   "source": [
    "## Continuous Speech Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2658c8e5-e0dd-4a82-9b61-0b903d10c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "class ContinuousSpeechRecognition():\n",
    "    def __init__(self):\n",
    "        self.lextree=None\n",
    "    # get the information from lextree    \n",
    "    def get_tree_info(self,root,edge_cost):\n",
    "        self.lextree=root\n",
    "        self.get_nodes(self.lextree)\n",
    "        self.edge_cost=edge_cost\n",
    "        self.previous={}\n",
    "        self.next={}\n",
    "        self.end_nodes=[]\n",
    "        for i in range(len(self.nodes)):\n",
    "            node=self.nodes[i]\n",
    "            # if the state of the node is 1, it is the end of a word(digit)\n",
    "            if node.state==1:\n",
    "                self.end_nodes.append(i)\n",
    "            self.next[i]=[]\n",
    "            if len(node.next)>0:\n",
    "                for next_node in node.next:\n",
    "                    # get the previous node(s) and next node(s) for each node\n",
    "                    self.next[i].append(self.nodes.index(next_node))\n",
    "                    self.previous[self.nodes.index(next_node)]=i\n",
    "\n",
    "    def get_nodes(self,root):\n",
    "        self.nodes=[root]\n",
    "        self.init_nodes=[]\n",
    "        self.states=[0]\n",
    "        for node in root.next:\n",
    "            state=0\n",
    "            curr_node=node\n",
    "            # add the first node of each word into init_nodes list\n",
    "            self.init_nodes.append(node)\n",
    "            # while the node is not the ending node of a word(digit)\n",
    "            while curr_node.state!=1:\n",
    "                state+=1\n",
    "                self.nodes.append(curr_node)\n",
    "                self.states.append(state)\n",
    "                curr_node=curr_node.next[0]\n",
    "            # add the ending node of a word to the nodes list\n",
    "            state+=1\n",
    "            self.nodes.append(curr_node)\n",
    "            self.states.append(state)\n",
    "\n",
    "    \n",
    "    # continuous speech recognition for 4 or 7 digits phone number\n",
    "    def digit_recognition_47(self,data,loop_cost=-100):\n",
    "        zeros=np.zeros(np.shape(data)[1])\n",
    "        data=np.vstack([zeros,data])\n",
    "        cols=len(data)\n",
    "        rows=len(self.nodes)\n",
    "        # cost matrix\n",
    "        costs=np.full([rows,cols],np.inf)\n",
    "        # the cost from the initial state '*' to other nodes\n",
    "        init_cost=copy.deepcopy(costs)\n",
    "        init_cost[0][0]=0\n",
    "        \n",
    "        all_costs=[init_cost]\n",
    "        for i in range(1,cols):\n",
    "            for j in range(len(all_costs)):\n",
    "                curr_costs=all_costs[j]\n",
    "                for k in range(1,rows):\n",
    "                    # calculate the log gaussian score of the vector in input data and the node\n",
    "                    score=mixture_log_Gaussian(self.nodes[k].val,data[i])\n",
    "                    cost=min(curr_costs[k][i-1]+self.edge_cost[self.nodes[k].word][self.states[k]][self.states[k]], #horizontal transition from itself\n",
    "                             curr_costs[self.previous[k]][i-1]+self.edge_cost[self.nodes[k].word][self.states[self.previous[k]]][self.states[k]]) # diagonal transition from its previous node\n",
    "                    # cost for this node = current best path score + edge cost + node cost (log Gaussian score)\n",
    "                    curr_costs[k][i]=cost+score\n",
    "                # find the index of the node with the minimum cost\n",
    "                min_index=np.argmin(curr_costs[:,i])\n",
    "                min_cost=min(curr_costs[:,i])\n",
    "                # when the minimum cost is at one of the end nodes\n",
    "                if min_index in self.end_nodes:\n",
    "                    #if the jth costs matrix is in the middle of the all costs, we've already get the word(digit)\n",
    "                    if len(all_costs)-1>j:\n",
    "                        next_costs=all_costs[j]\n",
    "                        next_costs[0,i]=min_cost+loop_cost\n",
    "                    # if the j is the last costs matrix of the all costs\n",
    "                    # create a new costs matrix for the alignment of a new digit, if the number of words (digits) is less than 7\n",
    "                    elif len(all_costs)<7:\n",
    "                        new_costs=copy.deepcopy(costs)\n",
    "                        new_costs[0,i]=min_cost+loop_cost\n",
    "                        all_costs.append(new_costs)\n",
    "        # according to the all_costs matrix to get the words(digits)\n",
    "        result=self.get_words_47(all_costs,i)\n",
    "        return result\n",
    "        \n",
    "        \n",
    "    def get_words_47(self,all_costs,i):\n",
    "        if len(all_costs)>=7:\n",
    "            # for 7 digits the costs matrix of the last digit is the 7th matrix\n",
    "            min_cost_7=min(all_costs[6][self.end_nodes,i])\n",
    "            # for 4 digits the costs matrix of the last digit is the 4th matrix\n",
    "            min_cost_4=min(all_costs[3][self.end_nodes,i])\n",
    "            \n",
    "            # judge whether the data is more likely to be 4 digits or 7 digits by their minimum costs\n",
    "            if min_cost_7<min_cost_4:\n",
    "                end_index=6\n",
    "            else:\n",
    "                end_index=3\n",
    "        else:\n",
    "            end_index=3\n",
    "            \n",
    "        result=''\n",
    "        # from the last word (digit) to the first\n",
    "        for j in range(end_index,-1,-1):\n",
    "            curr_word,i=self.get_curr_word(all_costs[j],i)\n",
    "            result=curr_word+result\n",
    "        return result\n",
    "\n",
    "    def get_curr_word(self,curr_costs,i):\n",
    "        # In the last col of the costs matrix, get the end node with minimum cost\n",
    "        min_index=np.argmin(curr_costs[self.end_nodes,i])\n",
    "        curr_node=self.end_nodes[min_index]\n",
    "        \n",
    "        while i>0 and curr_node>0:\n",
    "            min_previous_cost=min(curr_costs[curr_node][i-1],curr_costs[self.previous[curr_node]][i-1])\n",
    "            # horizontal move\n",
    "            if min_previous_cost==curr_costs[curr_node][i-1]:\n",
    "                i-=1\n",
    "            # diagonal move\n",
    "            elif min_previous_cost==curr_costs[self.previous[curr_node]][i-1]:\n",
    "                i-=1\n",
    "                curr_node=self.previous[curr_node]\n",
    "                \n",
    "        return self.nodes[self.end_nodes[min_index]].word,i\n",
    "\n",
    "    def digit_recognition(self,data,loop_cost=150):\n",
    "        zeros=np.zeros(np.shape(data)[1])\n",
    "        data=np.vstack([zeros,data])\n",
    "        cols=len(data)\n",
    "        rows=len(self.nodes)\n",
    "        # cost matrix\n",
    "        costs=np.full([rows,cols],np.inf)\n",
    "        costs[0][0]=0\n",
    "\n",
    "        for i in range(1,cols):\n",
    "            for j in range(1,rows):\n",
    "                # calculate the log gaussian score of the vector in input data and the node\n",
    "                score=mixture_log_Gaussian(self.nodes[j].val,data[i])\n",
    "                cost=min(costs[j][i-1]+self.edge_cost[self.nodes[j].word][self.states[j]][self.states[j]],#horizontal transition from itself\n",
    "                      costs[self.previous[j]][i-1]+self.edge_cost[self.nodes[j].word][self.states[self.previous[j]]][self.states[j]]) # diagonal transition from its previous node\n",
    "                if not cost==np.inf:\n",
    "                    costs[j][i]=cost+score\n",
    "            # find the index of the node with the minimum cost\n",
    "            min_index=np.argmin(costs[:,i])\n",
    "            min_cost=min(costs[:,i])\n",
    "            # when the minimum cost is at one of the end nodes\n",
    "            if min_index in self.end_nodes and min_cost!=np.inf:\n",
    "                # Now one word (digit) ends and we reach the non emitting state\n",
    "                # We assume the probability from non-emitting state to the init state of each digit is same.\n",
    "                # Thus, we only add the score for non-emitting state (the log probability from the end state of a digit to the non-emitting state)\n",
    "                min_end_node=self.end_nodes.index(min_index)\n",
    "                if min_end_node==10:\n",
    "                    word='silence'\n",
    "                else: \n",
    "                    word=str(min_end_node)\n",
    "                non_emitting_state_score=self.edge_cost[word][-1][-1]\n",
    "                costs[0,i]=min_cost+loop_cost+non_emitting_state_score\n",
    "        # according to the costs matrix to get the words(digits)\n",
    "        result=self.get_words(costs,i)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_words(self,costs,i):\n",
    "        result=''\n",
    "        while i>0:\n",
    "            curr_word,i=self.get_curr_word(costs,i)\n",
    "            result=curr_word+result\n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "772d50bf-3d3a-4e30-b5f0-499119d75fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "csr=ContinuousSpeechRecognition()\n",
    "csr.get_tree_info(root,edge_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a4cc1d-11a3-467d-8110-51f4f8dc359f",
   "metadata": {},
   "source": [
    "## Problem 2 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff058c56-2489-450c-939a-457ea72e691c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test phone num is 123456, the recongnition result is 123456\n",
      "The test phone num is 2212, the recongnition result is 2212\n",
      "The test phone num is 37472941, the recongnition result is 37472949\n",
      "The test phone num is 55555, the recongnition result is 555556\n",
      "The test phone num is 6890372344, the recongnition result is 6890372344\n",
      "The test phone num is 72184347924, the recongnition result is 7018434079249\n",
      "The test phone num is 7343332190377, the recongnition result is 7313332190377\n",
      "The test phone num is 8212176342, the recongnition result is 82121763429\n",
      "The test phone num is 826414052002, the recongnition result is 826414052002\n",
      "The test phone num is 911385, the recongnition result is 011385\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "foldername=\"test_data/Problem_2/\"\n",
    "folder=os.listdir(foldername)\n",
    "for filename in folder:\n",
    "    phone_num=filename[:-4]\n",
    "    data=getMFCC(foldername+filename)\n",
    "    result=csr.digit_recognition(data)\n",
    "    print(\"The test phone num is {}, the recongnition result is {}\".format(phone_num,result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1234b837-f33e-44d9-acbe-a5714ed4550c",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12c99120-88ed-465a-ad4c-ae20b4ba5145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.58823529411765%\n"
     ]
    }
   ],
   "source": [
    "wrong_digit_num=3+1+1+1+1+1\n",
    "total_digit_num=6+4+5+8+10+11+13+10+12+6\n",
    "print(\"Accuracy:\", str((1-wrong_digit_num/total_digit_num)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6022aed-eaf3-4a9f-a526-8f3a91c19d0c",
   "metadata": {},
   "source": [
    "# Project 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d95cd3-9509-4c31-a112-bc8cc7328f30",
   "metadata": {},
   "source": [
    "## Train an HMM model for 'silence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "838ba7e5-1dcd-401c-a458-37f47e9e6f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmm model silence trained\n"
     ]
    }
   ],
   "source": [
    "folder='silence_record'\n",
    "Gaussian_num=[2,2]\n",
    "words=['silence']\n",
    "silence_gmmhmm=GMMHMM(folder,Gaussian_num,words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "78856a06-f390-4972-b450-c6a40e83713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_models['silence']=silence_gmmhmm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bf51a584-47cb-4d07-97e6-ad2336a64194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_models['0'].num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47334d47-9379-4840-97cd-9759b2eef2a8",
   "metadata": {},
   "source": [
    "## Continuous recording training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "759d62df-ac18-46bf-b015-7e5d650de277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the inofrmation of each state\n",
    "class State:\n",
    "    def __init__(self,word,index):\n",
    "        # the word the state belongs to\n",
    "        self.word=word\n",
    "        # ith state\n",
    "        self.index=index\n",
    "        self.mean=[]\n",
    "        self.var=[]\n",
    "        self.weight=[]\n",
    "        # number of GMM\n",
    "        self.num=0\n",
    "        # the edge cost of a state is: [edge cost of self transition, edge cost to next state]\n",
    "        self.edge_cost=np.array([0,0])\n",
    "\n",
    "# store the information of each word\n",
    "class Word:\n",
    "    def __init__(self,word,state_num):\n",
    "        self.state_num=state_num\n",
    "        self.word=word\n",
    "        # store all the state class in a word\n",
    "        self.states=[]\n",
    "\n",
    "# continuous recording training class\n",
    "class CRT:\n",
    "    def __init__(self,words,sequences):\n",
    "        self.words=words\n",
    "        self.sequences=sequences\n",
    "        self.models={}\n",
    "        \n",
    "    # initialize the model by reconstruct the hmm model trained by single digit recording\n",
    "    # self.models['word']->Word, Word.states[state]->State\n",
    "    def init_models(self,hmm_models):\n",
    "        for word in self.words:\n",
    "            curr_hmm=hmm_models[word]\n",
    "            new_word=Word(word,curr_hmm.num)\n",
    "            for state in range(curr_hmm.num):\n",
    "                curr_state=curr_hmm.mix[state]\n",
    "                new_state=State(word,state)\n",
    "                new_state.mean=curr_state.mean\n",
    "                new_state.var=curr_state.var\n",
    "                new_state.weight=curr_state.weight\n",
    "                new_state.num=curr_state.num\n",
    "                # In the trained single digit hmm model, the edge cost matrix is put in the hmm class\n",
    "                # While, here we put the cost vector in each state class\n",
    "                new_state.edge_cost=curr_hmm.edge_cost[state+1,state+1:state+3]\n",
    "                new_word.states.append(new_state)\n",
    "            self.models[word]=new_word\n",
    "    # get training data (mfcc) of each word, and get concatenated sequence data\n",
    "    def get_data(self,foldername,i,j):\n",
    "        self.training_data={}\n",
    "        self.concatenated_models={}\n",
    "        for sequence in self.sequences:\n",
    "            self.training_data[sequence]=[]\n",
    "            # add mfcc spectrum of each recording to the training_data\n",
    "            for index in range(i,j):\n",
    "                spectrum=getMFCC(foldername+'/'+sequence+'_'+str(index)+'.wav')\n",
    "                self.training_data[sequence].append(spectrum)\n",
    "            self.concatenated_models[sequence]=[]\n",
    "            words=['silence']\n",
    "            # concatenate the GMMs in each state of a word as the required format 'silence+...+silence'\n",
    "            for digit in sequence:\n",
    "                words.append(digit)\n",
    "            words.append('silence')\n",
    "            for word in words:\n",
    "                curr_word_model=self.models[word]\n",
    "                for state in curr_word_model.states:\n",
    "                    self.concatenated_models[sequence].append(state)\n",
    "    \n",
    "    # initialize nodes_in_states and end_of_states for training\n",
    "    def init_training(self):\n",
    "        self.nodes_in_state={}\n",
    "        self.endnodes_in_state={}\n",
    "        for word in self.words:\n",
    "            self.nodes_in_state[word]={}\n",
    "            self.endnodes_in_state[word]={}\n",
    "            curr_word_model=self.models[word]\n",
    "            for state in range(curr_word_model.state_num):\n",
    "                self.nodes_in_state[word][state]=[]\n",
    "                self.endnodes_in_state[word][state]=0\n",
    "    \n",
    "    # training the hmm model\n",
    "    def train_model(self):\n",
    "        previous_cost=-np.inf\n",
    "        for i in range(99):\n",
    "            curr_cost=0\n",
    "            self.init_training()\n",
    "            for sequence in self.sequences:\n",
    "                # get trianing data\n",
    "                curr_training_data=self.training_data[sequence]\n",
    "                # get the concatenated model for the trianing data\n",
    "                curr_concatenated_model=self.concatenated_models[sequence]\n",
    "                for j in range(len(curr_training_data)):\n",
    "                    data=curr_training_data[j]\n",
    "                    cost=self.DTW(curr_concatenated_model,data)\n",
    "                    curr_cost+=cost\n",
    "            for word in self.words:\n",
    "                self.update_model(word)\n",
    "            if abs(previous_cost-curr_cost)<3:\n",
    "                break\n",
    "            previous_cost=curr_cost\n",
    "    \n",
    "    def update_model(self,word):\n",
    "        word_model=self.models[word]\n",
    "        for state in range(word_model.state_num):\n",
    "            state_model=word_model.states[state]\n",
    "            nodes=self.nodes_in_state[word][state]\n",
    "            gmm_model=self.Kmeans(nodes,state_model.num)\n",
    "            state_model.mean=gmm_model.mean\n",
    "            state_model.var=gmm_model.var\n",
    "            state_model.weight=gmm_model.weight\n",
    "            state_model.num=gmm_model.num\n",
    "            # the probability of self transition\n",
    "            prob=(len(nodes)-self.endnodes_in_state[word][state])/len(nodes)\n",
    "            state_model.edge_cost[0]=-np.log(prob)\n",
    "            state_model.edge_cost[1]=-np.log((1-prob))\n",
    "            print(word,state,state_model.edge_cost)\n",
    "    \n",
    "    # 没改变量名\n",
    "    def Kmeans(self,nodes_for_Kmeans,num_Gaussian_distribution):\n",
    "        #initialize with mean, var and weight, with one cluster\n",
    "        num_templates=len(nodes_for_Kmeans)\n",
    "        means=[]\n",
    "        covs=[]\n",
    "        weights=[1]\n",
    "        mean=np.mean(nodes_for_Kmeans,axis=0)\n",
    "        cov=np.diagonal(np.cov(np.array(nodes_for_Kmeans).T),offset=0, axis1=0, axis2=1)\n",
    "        means.append(mean)\n",
    "        covs.append(cov)\n",
    "        \n",
    "        current_num_of_cluster=1\n",
    "        episolom=0.04\n",
    "        #initial should be 1 mean\n",
    "        mix = GMMInfo()\n",
    "        mix.var = np.array(covs)\n",
    "        mix.mean = np.array(means)\n",
    "        mix.num = current_num_of_cluster\n",
    "        mix.weight = np.array(weights)\n",
    "        stop=False\n",
    "        \n",
    "        while num_Gaussian_distribution>current_num_of_cluster and not stop:\n",
    "            #now split\n",
    "            new_means=[]\n",
    "            new_covs=[]\n",
    "            current_num_of_cluster=current_num_of_cluster*2\n",
    "            new_clusters=[]\n",
    "            for cluster in range(len(means)):\n",
    "                #append newly two cluster center\n",
    "                new_clusters.append([])\n",
    "                new_clusters.append([])\n",
    "                #get splitted mean and cov\n",
    "                new_mean1=means[cluster]*(1-episolom)\n",
    "                new_mean2=means[cluster]*(1+episolom)\n",
    "                new_cov1=covs[cluster]*(1-episolom)\n",
    "                new_cov2=covs[cluster]*(1+episolom)\n",
    "                new_means.append(new_mean1)\n",
    "                new_means.append(new_mean2)\n",
    "                new_covs.append(new_cov1)\n",
    "                new_covs.append(new_cov2)\n",
    "            #now assign the templated into new clusters\n",
    "            new_means=np.array(new_means)\n",
    "            new_covs=np.array(new_covs)\n",
    "            for node in nodes_for_Kmeans:\n",
    "                d=log_Gaussian(new_means,new_covs,node)\n",
    "                cluster=np.argmin(d)\n",
    "                new_clusters[cluster].append(node)\n",
    "            #now, according to the new clustered result, we get updated weight,\n",
    "            #mean and cov\n",
    "            means=[]\n",
    "            covs=[]\n",
    "            weights=[]\n",
    "            #\n",
    "            # print(\"For {} clusters, each cluster has following nodes\".format(current_num_of_cluster))\n",
    "            for cluster in new_clusters:\n",
    "                # print(len(cluster))\n",
    "                if len(cluster)<2*num_Gaussian_distribution:\n",
    "                    stop=True\n",
    "                    # print(\"For this state, we only have 2 Gaussian Distributions\")\n",
    "                mean=np.mean(cluster,axis=0)\n",
    "                cov=np.cov(np.array(cluster).T)\n",
    "                # print(np.shape(cov))\n",
    "                cov=np.diagonal(cov,offset=0, axis1=0, axis2=1)\n",
    "                weight=len(cluster)/num_templates\n",
    "                means.append(mean)\n",
    "                covs.append(cov)\n",
    "                weights.append(weight)\n",
    "            #print(np.sum(weights))\n",
    "            # print(\"get {} means\".format(current_num_of_cluster))\n",
    "            # now, we put all the information to mix\n",
    "            mix = GMMInfo()\n",
    "            mix.var = np.array(covs)\n",
    "            mix.mean = np.array(means)\n",
    "            mix.num = current_num_of_cluster\n",
    "            mix.weight = np.array(weights)\n",
    "        return mix\n",
    "\n",
    "    def DTW(self,curr_concatenated_model,data):\n",
    "        zeros=np.zeros(39)\n",
    "        data=np.vstack([zeros,data])\n",
    "        col=len(data)\n",
    "        row=len(curr_concatenated_model)\n",
    "        costs=np.full((row,col),np.inf)\n",
    "        costs[0][0]=0\n",
    "        for i in range(1,col):\n",
    "            for j in range(row):\n",
    "                cost=mixture_log_Gaussian(curr_concatenated_model[j],data[i])\n",
    "                score=min(costs[j][i-1]+curr_concatenated_model[j].edge_cost[0],\n",
    "                       costs[j-1][i-1]+curr_concatenated_model[j-1].edge_cost[1])\n",
    "                if not score==np.inf:\n",
    "                    costs[j][i]=score+cost\n",
    "        self.get_result(costs,i,j,curr_concatenated_model,data)\n",
    "        min_cost=costs[-1][-1]/len(data)\n",
    "        return min_cost\n",
    "\n",
    "    def get_result(self,costs,i,j,curr_concatenated_model,data):\n",
    "        previous_state=curr_concatenated_model[-1].index\n",
    "        while i>0 and j>0:\n",
    "            previous_costs=[costs[j][i-1],costs[j-1][i-1]]\n",
    "            idx=np.argmin(previous_costs)\n",
    "            if idx==0:\n",
    "                i=i-1\n",
    "            elif idx==1:\n",
    "                i=i-1\n",
    "                j=j-1\n",
    "            node=data[i]\n",
    "            word=curr_concatenated_model[j].word\n",
    "            state=curr_concatenated_model[j].index\n",
    "            self.nodes_in_state[word][state].append(node)\n",
    "            if previous_state!=state:\n",
    "                self.endnodes_in_state[word][state]+=1\n",
    "                previous_state=state\n",
    "        \n",
    "            \n",
    "\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e62ba43c-3935-4998-a6d0-cc9cc3708aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all 10 words\n",
    "words=[str(i) for i in range(10)]\n",
    "words.append('silence')\n",
    "sequences=['0123456789','9876543210','1234567890','0987654321','1357902468','8642097531']\n",
    "foldername='project_6_training_data'\n",
    "\n",
    "crt=CRT(words,sequences)\n",
    "crt.init_models(hmm_models)\n",
    "crt.get_data(foldername,0,5)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8d7a2e70-3429-45b3-968a-8ee4f28ef067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[        inf -0.                 inf         inf         inf  0.        ]\n",
      " [ 0.          0.02915658  3.54961739         inf         inf  0.        ]\n",
      " [ 0.          0.          0.05026183  3.0155349          inf  0.        ]\n",
      " [ 0.          0.          0.          0.07878088  2.58021683  0.        ]\n",
      " [ 0.          0.          0.          0.         -0.         -3.42100001]]\n"
     ]
    }
   ],
   "source": [
    "print(hmm_models['0'].edge_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "44e121df-7d43-4f6c-b787-8c6cac03cd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02469261, 3.37709983])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crt.models['silence'].states[0].edge_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9c51ee23-b6b3-4af7-a96e-4983556bdf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 [0.02700434 3.62522943]\n",
      "0 1 [0.05009395 3.01879755]\n",
      "0 2 [0.06947237 2.70136121]\n",
      "0 3 [0.05536469 2.92136786]\n",
      "1 0 [0.04380262 3.14988295]\n",
      "1 1 [0.06524052 2.76211742]\n",
      "1 2 [0.04710447 3.07884718]\n",
      "1 3 [0.31845373 1.29928298]\n",
      "2 0 [0.05368015 2.95143201]\n",
      "2 1 [0.11419237 2.22642373]\n",
      "2 2 [0.05526268 2.92316158]\n",
      "2 3 [0.05849621 2.8678989 ]\n",
      "3 0 [0.03866461 3.27210059]\n",
      "3 1 [0.14041718 2.03252462]\n",
      "3 2 [0.04831858 3.05400118]\n",
      "3 3 [0.12675171 2.12823171]\n",
      "4 0 [0.06385147 2.78295151]\n",
      "4 1 [0.10801858 2.27897523]\n",
      "4 2 [0.11506933 2.21920348]\n",
      "4 3 [0.0547582  2.93208225]\n",
      "5 0 [0.06467771 2.77050322]\n",
      "5 1 [0.09500811 2.40092099]\n",
      "5 2 [0.06252036 2.80336038]\n",
      "5 3 [0.08726464 2.48212501]\n",
      "6 0 [0.05556985 2.91777073]\n",
      "6 1 [0.0447836  3.12822146]\n",
      "6 2 [0.0631789  2.79320801]\n",
      "6 3 [1.55814462 0.23638878]\n",
      "7 0 [0.13176928 2.09186406]\n",
      "7 1 [0.10283024 2.32565037]\n",
      "7 2 [0.02620237 3.6549779 ]\n",
      "7 3 [0.16251893 1.89711998]\n",
      "8 0 [0.0338251  3.40341714]\n",
      "8 1 [0.05495888 2.92852352]\n",
      "8 2 [0.12568822 2.13613689]\n",
      "8 3 [0.06087072 2.82928407]\n",
      "9 0 [0.04399536 3.14558803]\n",
      "9 1 [0.07940678 2.57261223]\n",
      "9 2 [0.03871451 3.27083556]\n",
      "9 3 [3.4339872  0.03278982]\n",
      "silence 0 [0.06297989 2.79626456]\n",
      "silence 1 [0.3844117 1.1420974]\n",
      "0 0 [0.03171513 3.46677703]\n",
      "0 1 [0.04902943 3.03974916]\n",
      "0 2 [0.07028653 2.6901125 ]\n",
      "0 3 [0.06252036 2.80336038]\n",
      "1 0 [0.03836788 3.2796573 ]\n",
      "1 1 [0.05526268 2.92316158]\n",
      "1 2 [0.04688359 3.08343785]\n",
      "1 3 [0.16164135 1.90210753]\n",
      "2 0 [0.12310606 2.15563068]\n",
      "2 1 [0.09811786 2.37024374]\n",
      "2 2 [0.05264373 2.97041447]\n",
      "2 3 [0.05598477 2.91053743]\n",
      "3 0 [0.03836788 3.2796573 ]\n",
      "3 1 [0.17086906 1.85107605]\n",
      "3 2 [0.05505978 2.9267394 ]\n",
      "3 3 [0.08246428 2.53633882]\n",
      "4 0 [0.08626034 2.49320545]\n",
      "4 1 [0.09411329 2.40994361]\n",
      "4 2 [0.11290173 2.23715729]\n",
      "4 3 [0.05651221 2.90142159]\n",
      "5 0 [0.07112001 2.67873581]\n",
      "5 1 [0.08292041 2.53104781]\n",
      "5 2 [0.07579384 2.61739583]\n",
      "5 3 [0.06087072 2.82928407]\n",
      "6 0 [0.05989814 2.84490938]\n",
      "6 1 [0.04573968 3.10757176]\n",
      "6 2 [0.06099451 2.82731362]\n",
      "6 3 [0.3844117 1.1420974]\n",
      "7 0 [0.14878874 1.97869997]\n",
      "7 1 [0.09500811 2.40092099]\n",
      "7 2 [0.02707747 3.62256157]\n",
      "7 3 [0.12111558 2.17095665]\n",
      "8 0 [0.0798296  2.56751018]\n",
      "8 1 [0.04725288 3.07577498]\n",
      "8 2 [0.19290367 1.74046617]\n",
      "8 3 [0.05485836 2.93030447]\n",
      "9 0 [0.07775936 2.59276405]\n",
      "9 1 [0.0631789  2.79320801]\n",
      "9 2 [0.04458391 3.13259146]\n",
      "9 3 [2.39789527 0.09531018]\n",
      "silence 0 [0.05732228 2.88759011]\n",
      "silence 1 [0.02876517 3.56293823]\n",
      "0 0 [0.0547582  2.93208225]\n",
      "0 1 [0.04863195 3.04769201]\n",
      "0 2 [0.07180117 2.66954035]\n",
      "0 3 [0.06467771 2.77050322]\n",
      "1 0 [0.05120572 2.99739755]\n",
      "1 1 [0.05455898 2.93562835]\n",
      "1 2 [0.05200478 2.98230925]\n",
      "1 3 [0.11686434 2.20460468]\n",
      "2 0 [0.11290173 2.23715729]\n",
      "2 1 [0.1100009 2.2617631]\n",
      "2 2 [0.05320404 2.9601051 ]\n",
      "2 3 [0.05505978 2.9267394 ]\n",
      "3 0 [0.03797925 3.2896449 ]\n",
      "3 1 [0.19044696 1.75209421]\n",
      "3 2 [0.06087072 2.82928407]\n",
      "3 3 [0.06979576 2.6968769 ]\n",
      "4 0 [0.10247867 2.3289024 ]\n",
      "4 1 [0.09265883 2.42480273]\n",
      "4 2 [0.10880286 2.27212589]\n",
      "4 3 [0.05683347 2.89591194]\n",
      "5 0 [0.07447609 2.63428405]\n",
      "5 1 [0.08047235 2.55980796]\n",
      "5 2 [0.08675958 2.48768058]\n",
      "5 3 [0.05218575 2.97892516]\n",
      "6 0 [0.06239029 2.80537855]\n",
      "6 1 [0.04580954 3.10608033]\n",
      "6 2 [0.06252036 2.80336038]\n",
      "6 3 [0.20340107 1.69255282]\n",
      "7 0 [0.17086906 1.85107605]\n",
      "7 1 [0.09381876 2.41293315]\n",
      "7 2 [0.02747426 3.60821155]\n",
      "7 3 [0.10763066 2.28238239]\n",
      "8 0 [0.08246428 2.53633882]\n",
      "8 1 [0.0491097  3.03815299]\n",
      "8 2 [0.20763936 1.67397643]\n",
      "8 3 [0.05339346 2.95664488]\n",
      "9 0 [0.12160713 2.16714712]\n",
      "9 1 [0.06538276 2.76000994]\n",
      "9 2 [0.0441248  3.14271446]\n",
      "9 3 [1.79175947 0.18232156]\n",
      "silence 0 [0.05511036 2.92584615]\n",
      "silence 1 [0.01611206 4.13623265]\n",
      "0 0 [0.06654339 2.74298825]\n",
      "0 1 [0.04886966 3.04293388]\n",
      "0 2 [0.0724955  2.66025954]\n",
      "0 3 [0.06669137 2.74084002]\n",
      "1 0 [0.05672598 2.89775187]\n",
      "1 1 [0.05416486 2.94268305]\n",
      "1 2 [0.05918887 2.85647021]\n",
      "1 3 [0.09716375 2.37954613]\n",
      "2 0 [0.10178269 2.33537492]\n",
      "2 1 [0.12361396 2.1517622 ]\n",
      "2 2 [0.05368015 2.95143201]\n",
      "2 3 [0.05445992 2.9373967 ]\n",
      "3 0 [0.03788332 3.29212629]\n",
      "3 1 [0.20202663 1.69866905]\n",
      "3 2 [0.06412453 2.77881927]\n",
      "3 3 [0.06524052 2.76211742]\n",
      "4 0 [0.11247798 2.24070969]\n",
      "4 1 [0.09411329 2.40994361]\n",
      "4 2 [0.10318424 2.32238772]\n",
      "4 3 [0.05726755 2.88851819]\n",
      "5 0 [0.07617895 2.61251777]\n",
      "5 1 [0.08025696 2.56238196]\n",
      "5 2 [0.09124867 2.43944428]\n",
      "5 3 [0.04879016 3.04452244]\n",
      "6 0 [0.06412453 2.77881927]\n",
      "6 1 [0.04573968 3.10757176]\n",
      "6 2 [0.06439993 2.77466989]\n",
      "6 3 [0.14448158 2.00597439]\n",
      "7 0 [0.19542478 1.72870133]\n",
      "7 1 [0.09470795 2.40393759]\n",
      "7 2 [0.02760065 3.60368461]\n",
      "7 3 [0.10283024 2.32565037]\n",
      "8 0 [0.08004271 2.56494936]\n",
      "8 1 [0.05129329 2.99573227]\n",
      "8 2 [0.21667104 1.63575522]\n",
      "8 3 [0.05245958 2.97382744]\n",
      "9 0 [0.13176928 2.09186406]\n",
      "9 1 [0.06524052 2.76211742]\n",
      "9 2 [0.04399536 3.14558803]\n",
      "9 3 [1.31567679 0.31237469]\n",
      "silence 0 [0.05296913 2.96441359]\n",
      "silence 1 [0.01485911 4.21656219]\n"
     ]
    }
   ],
   "source": [
    "crt.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f2444370-5b6b-48ea-9d91-0dce6fe6af30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06669137, 2.74084002])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crt.models['0'].states[3].edge_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "03710214-7bd7-41cc-9fbe-6f2fce07b0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_hmm_models={}\n",
    "for word in words:\n",
    "    curr_word_model=crt.models[word]\n",
    "    hmm=HMMInfo()\n",
    "    hmm.num=curr_word_model.state_num\n",
    "    hmm.mix=curr_word_model.states\n",
    "    hmm.edge_cost=np.zeros([hmm.num+1,hmm.num+2])\n",
    "    for state in range(hmm.num):\n",
    "        curr_state_model=hmm.mix[state]\n",
    "        hmm.edge_cost[state+1,state+1:state+3]=curr_state_model.edge_cost\n",
    "    new_hmm_models[word]=hmm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5345ae9f-aadf-410e-8d10-bd5e9e959faf",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3f1d2630-f1af-4c6f-bd1f-d4ae13ed2f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lextree=LexicalTree(new_hmm_models)\n",
    "lextree.GenerateTree()\n",
    "root=lextree.root\n",
    "edge_cost=lextree.edge_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "861e96e9-6ed1-4eee-83b6-a9e02b953b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "csr=ContinuousSpeechRecognition()\n",
    "csr.get_tree_info(root,edge_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "97074f46-2cec-4cc7-aa08-8e43e41d48bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test phone num is 0123456789_0, the recongnition result is 10123456789\n",
      "The test phone num is 0123456789_1, the recongnition result is 10123456789silence\n",
      "The test phone num is 0123456789_2, the recongnition result is 10123456789silence\n",
      "The test phone num is 0123456789_3, the recongnition result is 10123456789silence\n",
      "The test phone num is 0123456789_4, the recongnition result is 10123456781silence\n",
      "The test phone num is 0987654321_0, the recongnition result is 10987654321silence\n",
      "The test phone num is 0987654321_1, the recongnition result is 10987654321silence\n",
      "The test phone num is 0987654321_2, the recongnition result is silence098silence7654321\n",
      "The test phone num is 0987654321_3, the recongnition result is 1987654silence321silence\n",
      "The test phone num is 0987654321_4, the recongnition result is 1098silence7654321silence\n",
      "The test phone num is 1234567890_0, the recongnition result is 1234567890silence\n",
      "The test phone num is 1234567890_1, the recongnition result is 1234567890silence\n",
      "The test phone num is 1234567890_2, the recongnition result is 1234567890silence\n",
      "The test phone num is 1234567890_3, the recongnition result is 1234567890silence\n",
      "The test phone num is 1234567890_4, the recongnition result is 1234567890silence\n",
      "The test phone num is 1357902468_0, the recongnition result is 1357902silence468silence\n",
      "The test phone num is 1357902468_1, the recongnition result is 1357silence902468silence\n",
      "The test phone num is 1357902468_2, the recongnition result is 13579024silence68silence\n",
      "The test phone num is 1357902468_3, the recongnition result is 1357902468silence\n",
      "The test phone num is 1357902468_4, the recongnition result is 13579024silence68silence\n",
      "The test phone num is 8642097531_0, the recongnition result is 12097531silence\n",
      "The test phone num is 8642097531_1, the recongnition result is 18642097531silence\n",
      "The test phone num is 8642097531_2, the recongnition result is 18642097531silence\n",
      "The test phone num is 8642097531_3, the recongnition result is 1642097531\n",
      "The test phone num is 8642097531_4, the recongnition result is 18612097531silence\n",
      "The test phone num is 9876543210_0, the recongnition result is 1876543210silence\n",
      "The test phone num is 9876543210_1, the recongnition result is 19876543210silence\n",
      "The test phone num is 9876543210_2, the recongnition result is 19876543210silence\n",
      "The test phone num is 9876543210_3, the recongnition result is 1876543210silence\n",
      "The test phone num is 9876543210_4, the recongnition result is 19876543210silence\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "foldername=\"project_6_training_data/\"\n",
    "folder=os.listdir(foldername)\n",
    "for filename in folder:\n",
    "    phone_num=filename[:-4]\n",
    "    data=getMFCC(foldername+filename)\n",
    "    result=csr.digit_recognition(data)\n",
    "    print(\"The test phone num is {}, the recongnition result is {}\".format(phone_num,result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
